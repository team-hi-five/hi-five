<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Microphone to Speaker</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      display: flex;
      justify-content: center;
      align-items: center;
      height: 100vh;
      margin: 0;
      background-color: #f0f0f0;
    }
    #toggleAudio {
      font-size: 18px;
      padding: 10px 20px;
      cursor: pointer;
      background-color: #4CAF50;
      color: white;
      border: none;
      border-radius: 5px;
      transition: background-color 0.3s;
    }
    #toggleAudio:hover {
      background-color: #45a049;
    }
  </style>
</head>
<body>
  <button id="toggleAudio">Start Audio</button>

  <script>
    const BUFFER_SIZE = 4800;
    class Player {
      constructor() {
        this.playbackNode = null;
      }
      async init(sampleRate) {
        const audioContext = new AudioContext({ sampleRate });
        await audioContext.audioWorklet.addModule("/static/audio-playback-worklet.js");
        this.playbackNode = new AudioWorkletNode(audioContext, "audio-playback-worklet");
        this.playbackNode.connect(audioContext.destination);
      }
      play(buffer) {
        if (this.playbackNode) {
          this.playbackNode.port.postMessage(buffer);
        }
      }
      stop() {
        if (this.playbackNode) {
          this.playbackNode.port.postMessage(null);
        }
      }
    }

    class Recorder {
      constructor(onDataAvailable) {
        this.onDataAvailable = onDataAvailable;
        this.audioContext = null;
        this.mediaStream = null;
        this.mediaStreamSource = null;
        this.workletNode = null;
      }
      async start(stream) {
        try {
          if (this.audioContext) {
            await this.audioContext.close();
          }
          this.audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 24000 });
          await this.audioContext.audioWorklet.addModule("/static/audio-processor-worklet.js");
          this.mediaStream = stream;
          this.mediaStreamSource = this.audioContext.createMediaStreamSource(this.mediaStream);
          this.workletNode = new AudioWorkletNode(this.audioContext, "audio-processor-worklet");
          this.workletNode.port.onmessage = event => {
            this.onDataAvailable(event.data.buffer);
          };
          this.mediaStreamSource.connect(this.workletNode);
          this.workletNode.connect(this.audioContext.destination);
        } catch (error) {
          this.stop();
        }
      }
      async stop() {
        if (this.mediaStream) {
          this.mediaStream.getTracks().forEach(track => track.stop());
          this.mediaStream = null;
        }
        if (this.audioContext) {
          await this.audioContext.close();
          this.audioContext = null;
        }
        this.mediaStreamSource = null;
        this.workletNode = null;
      }
    }

    // --- 강제 종료 및 버튼 제어를 위한 전역 변수 ---
    const botHelloAudio = new Audio('/static/bot_voice/bot_hello.mp3');
    const botByeAudio = new Audio('/static/bot_voice/bot_bye.mp3');

    let ws = null;
    let audioRecorder = null;
    let isAudioOn = false;
    let isTerminated = false;  // 세션 종료 여부
    let conversationCount = 0; // 대화 회차 카운터

    // --- 마이크 중지를 수행하는 함수 ---
    function disableMicrophone() {
      if (isTerminated) return;
      isTerminated = true;
      console.log("Disabling microphone: conversation rounds reached.");

      // (선택) bot_bye 오디오 재생
      botByeAudio.play().catch(err => console.error("Error playing botByeAudio:", err));

      // 마이크 스트림 중지
      if (audioRecorder && audioRecorder.mediaStream) {
        audioRecorder.mediaStream.getTracks().forEach(track => track.stop());
      }
      if (audioRecorder) {
        audioRecorder.stop();
        audioRecorder = null;
      }
      if (ws) {
        ws.close();
        ws = null;
      }
      // 버튼 업데이트: 재시작 불가
      const toggleButton = document.getElementById('toggleAudio');
      toggleButton.textContent = 'Session Terminated';
      toggleButton.disabled = true;
      isAudioOn = false;
    }

    async function startAudio() {
      try {
        // 인사 오디오 재생
        await botHelloAudio.play();
        console.log('botHelloAudio played successfully.');
      } catch (err) {
        console.error('Error playing botHelloAudio:', err);
        alert('Failed to play the greeting audio. Please check that the audio file is available.');
        return;
      }

      // 인사 오디오 후 5초 대기
      await new Promise(resolve => setTimeout(resolve, 5000));

      try {
        ws = new WebSocket("ws://localhost:3000/ws");
        const audioPlayer = new Player();
        await audioPlayer.init(24000);

        ws.onmessage = event => {
          if (isTerminated) return;

          const data = JSON.parse(event.data);

          // 대화 회차 카운트: transcript 필드가 있고, 해당 메시지 타입이 transcript 관련 타입 또는 모델 출력 타입이면 카운트 증가
          if (
            (data.type === "response.audio_transcript.done" || data.type === "response.output_item.added")
            && data.transcript && data.transcript.trim() !== ""
          ) {
            conversationCount++;
            console.log("Conversation count:", conversationCount);
            if (conversationCount >= 3) {
              disableMicrophone();
              return;
            }
          }

          if (data?.type === 'response.audio.delta') {
            const binary = atob(data.delta);
            const bytes = Uint8Array.from(binary, c => c.charCodeAt(0));
            const pcmData = new Int16Array(bytes.buffer);
            audioPlayer.play(pcmData);
          }
        };

        let buffer = new Uint8Array();
        const appendToBuffer = (newData) => {
          const newBuffer = new Uint8Array(buffer.length + newData.length);
          newBuffer.set(buffer);
          newBuffer.set(newData, buffer.length);
          buffer = newBuffer;
        };

        const handleAudioData = (data) => {
          const uint8Array = new Uint8Array(data);
          appendToBuffer(uint8Array);
          if (buffer.length >= BUFFER_SIZE) {
            const toSend = new Uint8Array(buffer.slice(0, BUFFER_SIZE));
            buffer = new Uint8Array(buffer.slice(BUFFER_SIZE));
            const regularArray = String.fromCharCode(...toSend);
            const base64 = btoa(regularArray);
            ws.send(JSON.stringify({ type: 'input_audio_buffer.append', audio: base64 }));
          }
        };

        audioRecorder = new Recorder(handleAudioData);
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        await audioRecorder.start(stream);

      } catch (error) {
        console.error('Error accessing the microphone or setting up audio processing:', error);
        alert('Error accessing the microphone or audio processing. Please check your settings and try again.');
      }
    }

    // --- 버튼 클릭 이벤트 ---
    const toggleButton = document.getElementById('toggleAudio');
    toggleButton.addEventListener('click', async () => {
      if (isTerminated) {
        alert("Session has been terminated.");
        return;
      }
      if (!isAudioOn) {
        conversationCount = 0;   // 대화 회차 카운터 초기화
        isTerminated = false;
        await startAudio();
        toggleButton.textContent = 'Stop Audio';
        isAudioOn = true;
      } else {
        if (ws) ws.close();
        if (audioRecorder) await audioRecorder.stop();
        toggleButton.textContent = 'Start Audio';
        isAudioOn = false;
      }
    });
  </script>
</body>
</html>
